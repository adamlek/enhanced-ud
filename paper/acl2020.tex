%
% File acl2020.tex
%
%% Based on the style files for ACL 2020, which were
%% Based on the style files for ACL 2018, NAACL 2018/19, which were
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2020}
\usepackage{times}
\usepackage{latexsym}
\renewcommand{\UrlFont}{\ttfamily\small}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

%\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\usepackage{subcaption}
\usepackage[capitalize]{cleveref}
\usepackage{tikz}
\usetikzlibrary{arrows,positioning,fit,shapes}
\usepackage{todonotes}
\usepackage{tikz-dependency}

\newcommand\BibTeX{B\textsc{ib}\TeX}

\title{How much of enhanced UD is contained in UD?}
% How enhanced is enhanced UD?

\author{First Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  \texttt{email@domain} \\\And
  Second Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  \texttt{email@domain} \\}

\date{}

\begin{document}
\maketitle
\begin{abstract}
  TODO
\end{abstract}

\section{Introduction}
(ADAM)

% UD intro
Universal Dependencies (UD) is a syntactic annotation schema
focusing on representing shallow syntactic dependencies between
words. One of the goals of UD has been to use it in semantic
downstream tasks, such as X or Y. However, basic dependencies
between words contain many implicit dependencies related to the
semantic interpretation of a sentence.

% EUD intro
to make the dependencies explicit the Enhanced Universal
Dependencies (EUD) schema was created. The goal of the schema is
to make certain semantic dependencies more explicit, such as
conjoined subject and object. The enhanced dependencies include
additional edges between words, aswell as augmented labels. For
example in enhanced dependencies, the conjunction relation also
include what type of conjunction is used, \textit{and, or, but}
and so on.

% What we do in this paper
In this paper we present our submission for the IWPT 2020 Shared
Task for parsing enhanced universal dependencies. We use a
tree-rewriting approach based on syntactic pattern in the basic
universal dependencies to derive enhanced dependencies.


    
% What do we want to show
We chose this approach because in many cases enhanced dependencies
are functions of the basic dependencies. Thus, our approach pose
the hypothesis:
\begin{enumerate}
    \item Most information about EUD is contained in UD
\end{enumerate}


    
% How we show this
We explore this by applying our approach to gold UD trees and
observe how much of the enhanced dependencies are captured.

    
%General idea: as described by the website
%(https://universaldependencies.org/u/overview/enhanced-syntax.html)
%for many cases, enhanced UD is a function of UD.
   
    
%Hypothesis: most information about EUD is already contained in UD.

% Shared task introduction
In the shared task, teams are asked to produce enhanced
dependencies from raw texts in 17 different languages. The
majority of the languages are indo-european with two notable
exceptions, Tamil (Dravidian) and Finnish (Uralic).

The task is evaluated using two metrics, ELAS and EULAS. ELAS
calculates the $F_1$-score over all enhanced dependencies, the
metric include both edges and edge labels. A secondary metric,
EULAS, is used which calculates the $F_1$-score over the edges
only.

-Implement the function for the common case, and see how we fare on the

% results in two lines
Our results on the shared task show that our method is effective,
both using machine generated and human annotated dependency
trees. On average, our approach achieves an ELAS score of $67.85$
and an EULAS score of $80.18$ on machine generated trees. However,
we show that given human annotated trees the scores increase by
around $15\%$.

In addition to performing well, our approach is efficient and only
require a few seconds to generate enhanced graphs from a
treebank.
    
%Results in 2 lines:
%- scores
%- efficient
%- transparent{}



\section{Method}
In essence, our method is to apply the tree rewrite recipies
provided in TODO to transform basic UD \emph{trees} into EUD
graphs.

We obtain basic UD trees (i.e. without enhanced dependencies) from two sources:
\begin{itemize}
\item 
for each treebank using the Stanford
Biaffine Dependency Parser~citep{dozat2016deep} provided in
Stanza \citep{qi2020stanza}. TODO: what are the source texts?
\item
  TODO the development (or gold) trees, minus the enhanced
  dependencies (those contain the simple trees, yay.)
\end{itemize}

Then, we use a tree-matching procedure against the UD trees, and
locally insert edges corresponding to enhanced dependencies (and
sometimes delete unwanted edges). As a particular case, we may
re-label some edges. Once this is done, we convert the result back to
(enhanced) CONLL format.

Perhaps surprisingly, the patterns that we need to recognize are
simple, involving only three nodes. The two patterns to recognised are
shown in \cref{fig:patterns}. Essentially, we need to match on three
connected nodes.  We need to identify types of paterns. First, two
arcs forming a two-step path
(\cref{fig:pat-nsubj-conj,fig:pat-obl,fig:pat-rel}). We refer to this
style pattern as ``Type 1''.  Second, with two arcs pointing away from
a central node (\cref{fig:pat-aux-conj,fig:pat-xcomp}), refered to as
``Type 2''.
In both cases, we have additional constraints on the (edge) labels. Together, constraint
on graph topology and labels form patterns which we recognize and transform.
The exhaustive list of patterns and transformations follows.
\begin{enumerate}
\item Type 1 pattern with a relation label, which can be any of
  ``nsubj",``obj", ``amod", ``advcl",``obl", ``mark", ``nmod", followed by a
  ``conj'' label. (\cref{fig:pat-nsubj-conj}.) In this case we add an
  edge with the relation label to the other conjunct.
  %
  A full dependency tree containing this pattern can be found in \cref{fig:paul-and-mary}.
  \label{item:paul-and-mary}
\item Type 2 pattern with a a relation label being either ``nsubj'' or
  ``aux'', and a ``conj'' label. (\cref{fig:pat-aux-conj}.) We add a relation a relation label to
  the other conjunct, but only if the conjunct is not itself
  ``nsubj''. Indeed, if it were, then we are conjoining two full
  sentences and then there is no need for an enhanced dependency.
  %
  A full dependency tree containing this pattern can be found in \cref{fig:reading-or-watching}.
  \label{item:reading-or-watching}
\item Type 2 pattern with ``xcomp'' and ``nsubj''. Here we add an
  "nsubj:xsubj" edge. (\cref{fig:pat-xcomp}.)
\item Type 1 pattern, with ``acl:relcl" followed by a relation label
  which can be either ``nsubj",``obj",``obl",
  "advmod". (\cref{fig:pat-rel}.) The target node should also be a
  \emph{relative} pronoun, ie. it POS is ``PRON'' and its XPOS either
  ``WP'' (who, whom) or ``WDT'' (that, which). Indeed, this pattern is
  also found with other type of pronouns, but then it does not
  correspond to a relative clause.  In this case we add a ref edge to
  the pronoun and a (reverse) relation edge between the first and
  second node. The original relation edge is deleted.\todo{check}
\item Type 1 pattern, with a conjunction followed by a case
  marking. (\cref{fig:pat-obl}.) Exhaustively, the type of labels are ``case" followed by
  ``obl" or ``nmod"; ``cc" followed by ``conj", ``mark" followed by ``advcl"
  or ``acl". In this case we enhance the label with the lemma of the target node.
\end{itemize}

\begin{figure}[h]
    \centering
    \begin{dependency}
    \begin{deptext}[column sep=1em]
    Paul \& and \& Mary \& eat \& . \\
    \end{deptext}
    \depedge{1}{3}{conj:and}
    \depedge{3}{2}{cc}
    \depedge{4}{1}{nsubj}
    \deproot{4}{root}
    \depedge{4}{5}{punct}
    \end{dependency}
    \caption{``Paul and Mary eat.''}
    \label{fig:paul-and-mary}
\end{figure}

\begin{figure}[h]
    \centering
    \begin{dependency}
    \begin{deptext}[column sep=1em]
    She \& was \& reading \& or \& watching \& something  \\
    \end{deptext}
    \depedge{3}{1}{nsubj}
    \depedge[edge below]{5}{1}{nsubj}
    \depedge{3}{6}{obj}
    \depedge[edge below]{5}{6}{obj}
    \deproot{3}{root}
    \depedge{3}{2}{aux}
    \depedge[edge below]{5}{3}{aux}
    \depedge{3}{5}{conj:or}
    \depedge{5}{4}{cc}
    \end{dependency}
    \caption{``She was reading or watching something''}
    \label{fig:reading-or-watching}
\end{figure}

\tikzstyle{word}=[ellipse,draw=blue!50,fill=blue!20,thick]
\tikzstyle{newedge}=[very thick]
\begin{figure}
\begin{subfigure}{\columnwidth}
  \centering
  \begin{tikzpicture}[inner sep=1mm]
    \node[word] (eat) {Eat};
    \node[word] (paul) [right=of eat] {Paul};
    \node[word] (mary) [right=of paul] {Mary};
    \draw[->] (eat) -- node[above] {nsubj} (paul);
    \draw[->] (paul) -- node[above] {conj} (mary);
    \path (eat) edge[->,newedge,bend right]  node[below] {nsubj} (mary);
  \end{tikzpicture}
  \caption{Relation pointing to the conjuncts}
  \label{fig:pat-nsubj-conj}
\end{subfigure}

\begin{subfigure}{\columnwidth}
  \centering
\begin{tikzpicture}[inner sep=1mm]
  \node[word] (was) {was};
  \node[word] (read) [right=of was] {read};
  \node[word] (watch) [right=of read] {watch};
  \draw[->] (read) -- node[above] {aux} (was);
  \draw[->] (read) -- node[above] {conj} (watch);
  \path (watch) edge[->,newedge,bend left]  node[below] {aux} (was);
\end{tikzpicture}

  \caption{Relation pointing away from the conjuncts.}
  \label{fig:pat-aux-conj}
\end{subfigure}

\begin{subfigure}{\columnwidth}
  \centering
\begin{tikzpicture}[inner sep=1mm]
  \node[word] (house) {house};
  \node[word] (look) [right=of house] {look};
  \node[word] (new) [right=of look] {new};
  \draw[->] (look) -- node[above] {nsubj} (house);
  \draw[->] (look) -- node[above] {xcomp} (new);
  \path (new) edge[->,newedge,bend left]  node[below] {xsubj:nsubj} (house);
\end{tikzpicture}

  \caption{Xcomp special case}
  \label{fig:pat-xcomp}
\end{subfigure}

\begin{subfigure}{\columnwidth}
  \centering
\begin{tikzpicture}[inner sep=1mm]
  \node[word] (from) {from};
  \node[word] (paris) [right=of from] {Paris};
  \node[word] (come) [right=of paris] {come};
  \draw[->] (paris) -- node[below] {case} (from);
  \draw[->] (come) -- node[below] (lab) {obl} (paris);
  \node at (lab.south) {\textbf{obl:from}};
\end{tikzpicture}
  \caption{Label taken from other word (lemma)}
  \label{fig:pat-obl}
\end{subfigure}

\begin{subfigure}{\columnwidth}
  \centering
  \begin{tikzpicture}[inner sep=1mm]
    \node[word] (boy) {boy};
    \node[word] (live) [right=of boy] {live};
    \node[word] (who) [right=of live] {who};
    \draw[->] (boy) -- node[above] {acl:recl} (live);
    \path  (live) edge[->,newedge,bend right] node[above] {nsubj} (boy);
    \draw[->] (live) -- node[above] {nsubj} (who);
    \path (boy) edge[->,newedge,bend right]  node[below] {ref} (who);
  \end{tikzpicture}
  \caption{Relative clause}
  \label{fig:pat-rel}
\end{subfigure}

\caption{Implemented transformation patterns. Added elements are shown in bold.}
  \label{fig:patterns}
\end{figure}

\begin{figure}
\begin{subfigure}{\columnwidth}
  \centering
  \begin{tikzpicture}[inner sep=1mm]
    \node[word] (eat) {Eat};
    \node[word] (paul) [right=of eat] {Paul};
    \node[word] (mary) [right=of paul] {Mary};
    \draw[->] (eat) -- node[above] {nsubj} (paul);
    \draw[->] (mary) -- node[above] {conj} (paul);
    \path (eat) edge[->,newedge,bend right]  node[below] {nsubj} (mary);
  \end{tikzpicture}
  \caption{Source pattern not representable in UD format}
  \label{fig:pat-nsubj-conj-bad}
\end{subfigure}

\begin{subfigure}{\columnwidth}
  \centering
\begin{tikzpicture}[inner sep=1mm]
  \node[word] (was) {was};
  \node[word] (read) [right=of was] {read};
  \node[word] (watch) [right=of read] {watch};
  \draw[->] (read) -- node[above] {aux} (was);
  \draw[->] (watch) -- node[above] {conj} (read);
  \path (watch) edge[->,newedge,bend left]  node[below] {aux} (was);
\end{tikzpicture}

  \caption{Transformation pattern leading to a loss in performance}
  \label{fig:pat-aux-conj-bad}
\end{subfigure}
\caption{Transformation patterns \textbf{not} implemented.}
\end{figure}



TODO Adam: dependency tree for this:

- John came from Paris
- some sentence with a relative clause


For patterns \cref{item:paul-and-mary,item:reading-or-watching}, the
conjunction dependency could conceptually be inverted, yielding two
other patterns (shown in
\cref{fig:pat-nsubj-conj-bad,fig:pat-aux-conj-bad}). However, we have
not implemented these patterns in our system. For the first pattern,
the reason is simple: it is not representable as a UD tree (a node
cannot have two parents). For the second pattern, applying it
results in a small loss in performance accross the board \todo{can we
  run this ?}, and thus it is best left inactive.

\section{Results}
(ADAM)

We present our official results for the shared task in
\cref{tab:test}. The scores are obtained by applying our method
to dependency trees generated by the Stanford Dependency Parser.
 

\begin{table}[h]
	\centering
	\begin{tabular}{l|rr}
		\textsc{Lang} & \textsc{EULAS} & \textsc{ELAS} \\
		\hline
		ar & 75.62 & 51.26 \\
		bg & 87.72 & 84.90 \\
		cs & 83.44 & 67.13 \\
		en & 83.86 & 82.87 \\
		et & 79.43 & 60.44 \\
		fi & 83.30 & 65.96 \\
		fr & 84.39 & 72.76 \\
		it & 88.74 & 87.14 \\
		lv & 80.60 & 66.01 \\
		nl & 80.20 & 78.93 \\
		lt & 67.37 & 52.56 \\
		pl & 86.71 & 71.22 \\
		ru & 88.02 & 70.37 \\
		sk & 83.31 & 65.16 \\
		sv & 73.84 & 71.35 \\
		ta & 55.32 & 42.15 \\
		uk & 81.24 & 63.24 \\
		\textbf{Avg.} & \textbf{80.18} & \textbf{67.85} \\
        \textbf{Std.} & \textbf{8.19} & \textbf{11.69} \\
	\end{tabular}
\caption{\label{tab:test} Coarse ELAS and EULAS on the languages in the test data.}
\end{table}

The results indicate that our system is more successfull at
finding the dependency edges compared to the dependency
labels. One large benefit of our system is that while it does
produce less than perfect output, in most cases the system may be
augmented such that these instances can be handled correctly.

To find an upper bound of our approach we also apply it to the
human annotated dependency trees. We test our approach on both
the development and test data. The results from this experiment
is shown in \cref{tab:gold-data}.
    
    
\begin{table}[ht]
	\centering
    \small
	\begin{tabular}{l|rrrr}
        & \multicolumn{2}{c}{\textsc{Dev}} & \multicolumn{2}{c}{\textsc{Test}} \\
		\textsc{Lang} & \textsc{ELAS} & \textsc{EULAS} & \textsc{ELAS} & \textsc{EULAS} \\
		\hline 
		ar & 66.44 & 96.38 & 64.14 & 96.55 \\
		bg & 94.32 & 96.95 & 94.55 & 97.01 \\
		cs & 75.65 & 94.63 & 76.52 & 95.12 \\
		en & 97.57 & 98.53 & 97.64 & 98.65 \\
		et & 73.35 & 93.96 & 72.30 & 95.53 \\
		fi & 74.22 & 95.29 & 74.40 & 95.12 \\
		fr & 83.59 & 97.93 & 88.15 & 99.05 \\
		it & 96.29 & 97.61 & 96.15 & 97.77 \\
		lt & 77.50 & 93.98 & 72.17 & 95.49 \\
		lv & 69.21 & 96.10 & 77.47 & 93.91 \\
		nl & 96.71 & 97.55 & 96.27 & 97.57 \\
		pl & 87.03 & 97.33 & 80.95 & 96.49 \\
		ru & 77.22 & 96.31 & 76.72 & 96.59 \\
		sk & 72.24 & 95.82 & 75.37 & 96.42 \\
		sv & 93.85 & 96.66 & 94.19 & 96.67 \\
		ta & 72.49 & 99.58 & 75.04 & 99.48 \\
		uk & 75.95 & 96.04 & 74.42 & 96.49 \\
		\textbf{Avg.} & \textbf{82.97}  & \textbf{96.53}& \textbf{81.55} & \textbf{96.70} \\
        Std. & 10.42 & 1.52 & 10.24 & 1.43 \\
	\end{tabular}
	\caption{\label{tab:gold-data}Coarse ELAS and EULAS on the gold trees in the development and test data.}
\end{table} 
%TODO: Add std dev.

We can observe again that the system does very well on the edges
(EULAS) while the performance on the label enhancements are
lower.

    
\section{Discussion/Analysis}


It works well on gold.
Performance on data is driven by quality of input trees also!

Labels work for english, ..., but not well for languages with
morphological case roles. Indeed, the pattern \cref{fig:pat-obl}
recognize case based on a preposition rather than a morphological
feature.

% one of the causes for lower labels score
Our simple approach works best for Bulgarian, English, Italian,
Dutch and Swedish, which all have fairly simple simple case
systems. The other languages have more complex system which
require additional fine-tuning of the label enhancements.

% second problem for our approach on labels
Our system also struggle with labels that include multi-word
tokens. For example, a valid adverbial clause modifier is
\textit{so\_that}. To solve these label enhancements our system
would need either a complete list of multi-word tokens, or be
able to figure them out using statistical or deep learning    
    
    
Secondary hyp: EUD do not help for learning EUD.

We do not know about this YET. For this we'd need to use compare a
state of art UD implementation.


To test that we'd need to run our system on the \emph{training} data
of a state of the art EUD system and see how that affects its
performance. But we can't do it since such systems are not available
yet (this is the purpose of the task ...).

Also can be used for bootstrapping.

Also: we provide a kind of a baseline.

The hypothesis is can be refuted on some simple example:

She was reading or watching a movie.

Even though ``a movie'' is an object of a verb conjunct, it should not
be propagated. But in some other cases it should. And this depends on
the semantics and pragmatics, and our system will not be able to make
a difference between these cases.

She was cleaning and eating fruits.

%Our system will also struggle with multi-word labels such as:
%\textsc{advcl:so-that}. To solve these label enhancements a
%system would need either a complete list of these multi-word
%tokens, or be able to figure them out using statistical or deep
%learning

    
\section*{Acknowledgments}

(Anonymized)

\bibliography{anthology,acl2020}
\bibliographystyle{acl_natbib}


\end{document}
